# -*- coding: utf-8 -*-
"""CS412_Proj_V2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jyiZyhcSYIOEB0C7L4ADbaXVRSrT7mfI
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sn
from math import isnan
from sklearn.preprocessing import OneHotEncoder

"""# Load the train data"""

from google.colab import drive
drive.mount('/content/drive')

trainDF = pd.read_excel("/content/train.xlsx")
testDF = pd.read_excel("/content/test.xlsx")

"""# Data Insight"""

grouped = trainDF.groupby(["Country"],as_index=False)["JobSatisfaction"].mean()
grouped = grouped.sort_values(by = "JobSatisfaction",ascending=False)
groupedValues = grouped["Country"].values[:10]
avgSatisfaction = grouped["JobSatisfaction"].values[:10]
plt.title('Avg Satisfaction by country')
plt.bar(groupedValues,avgSatisfaction)
plt.show()

grouped = trainDF.groupby(["Age"],as_index=False)["JobSatisfaction"].mean()
grouped = grouped.sort_values(by = "JobSatisfaction",ascending=False)
groupedValues = grouped["Age"].values
avgSatisfaction = grouped["JobSatisfaction"].values
plt.title('Avg Satisfaction by Age')
plt.bar(groupedValues,avgSatisfaction)
plt.show()

sn.set(rc={'figure.figsize':(16,10)},font_scale=1  )
pd.isnull(trainDF).sum().plot(kind='bar')
plt.ylabel('Missing Count')
plt.xlabel('Features')
plt.title('Missing Values over Feature');

grouped = trainDF.groupby("JobSatisfaction").agg("count")
x = grouped["ID"].values
y = [i for i in range(10)]
plt.plot(y,x)
plt.xlabel("Job Satisfaction")
plt.ylabel("Count")

trainDF.shape

trainDF.dtypes

info = pd.DataFrame(trainDF.info())

trainDF.nunique()

trainDF["CodeWriter"].isna().sum()

"""No nan values, all yes therefore this is not needed"""

# TRY
columnsToDrop = ["CodeWriter","GenderSelect","ID","RemoteWork","Country","MLTechniquesSelect","PastJobTitlesSelect"]
trainDF.drop(columns=columnsToDrop,inplace=True)
testDF.drop(columns=columnsToDrop,inplace=True)

display(trainDF.isna().any())

"""We see that this data frame has so much null values. Data should be cleaned from those values"""

trainDF.select_dtypes(include=np.number).columns.tolist() # numeric columns

"""Only numeric columns are ['ID', 'Age', 'CompensationScore', 'JobSatisfaction'] other columns should be converted into numerical values."""

trainDF.head()

tenureMap = {'3 to 5 years':0,'1 to 2 years':1,'6 to 10 years':2,'More than 10 years':3,'Less than a year':4,"I don't write code to analyze data":5}
trainDF["Tenure"] = trainDF["Tenure"].replace(tenureMap)
trainDF["Tenure"].fillna((trainDF["Tenure"].median()), inplace=True)
trainDF["Tenure"].unique()

testDF["Tenure"] = testDF["Tenure"].replace(tenureMap)
testDF["Tenure"].fillna((testDF["Tenure"].median()), inplace=True)
testDF["Tenure"].unique()

trainDF["EmployerSize"].unique()
sizeMap = {}
i = -1
for col in trainDF["EmployerSize"].unique():
  sizeMap[col] = i
  i = i+1
for k,v in sizeMap.items():
  if v == -1:
    sizeMap.pop(k)
    break
trainDF["EmployerSize"] = trainDF["EmployerSize"].replace(sizeMap)
trainDF["EmployerSize"].fillna((trainDF["EmployerSize"].median()), inplace=True)

testDF["EmployerSize"] = testDF["EmployerSize"].replace(sizeMap)
testDF["EmployerSize"].fillna((testDF["EmployerSize"].median()), inplace=True)

trainDF["WorkDataVisualizations"].unique()
visMap = {}
i = 0
for col in trainDF["WorkDataVisualizations"].unique():
  visMap[col] = i
  i = i+1

print(visMap)
for k,v in visMap.items():
  if v == 7:
    visMap.pop(k)
    break
trainDF["WorkDataVisualizations"] = trainDF["WorkDataVisualizations"].replace(visMap)
trainDF["WorkDataVisualizations"].fillna((trainDF["WorkDataVisualizations"].median()), inplace=True)

testDF["WorkDataVisualizations"] = testDF["WorkDataVisualizations"].replace(visMap)
testDF["WorkDataVisualizations"].fillna((testDF["WorkDataVisualizations"].median()), inplace=True)

trainDF.columns

freqMap =  {}

i = 0
for elt in trainDF["WorkProductionFrequency"].unique():
  freqMap[elt] = i
  i = i+1


for k,v in freqMap.items():
  if v == 6:
    freqMap.pop(k)
    break
print(freqMap)
freqMap["Often"] = 6

print(freqMap)

trainDF["WorkProductionFrequency"] = trainDF["WorkProductionFrequency"].replace(freqMap)
trainDF["WorkProductionFrequency"].fillna((trainDF["WorkProductionFrequency"].median()), inplace=True)

trainDF["WorkToolsFrequencyPython"] = trainDF["WorkToolsFrequencyPython"].replace(freqMap)
trainDF["WorkToolsFrequencyPython"].fillna((trainDF["WorkToolsFrequencyPython"].median()), inplace=True)

trainDF["WorkToolsFrequencyR"] = trainDF["WorkToolsFrequencyR"].replace(freqMap)
trainDF["WorkToolsFrequencyR"].fillna((trainDF["WorkToolsFrequencyR"].median()), inplace=True)

trainDF["WorkToolsFrequencySQL"] = trainDF["WorkToolsFrequencySQL"].replace(freqMap)
trainDF["WorkToolsFrequencySQL"].fillna((trainDF["WorkToolsFrequencySQL"].median()), inplace=True)




testDF["WorkProductionFrequency"] = testDF["WorkProductionFrequency"].replace(freqMap)
testDF["WorkProductionFrequency"].fillna((testDF["WorkProductionFrequency"].median()), inplace=True)

testDF["WorkToolsFrequencyPython"] = testDF["WorkToolsFrequencyPython"].replace(freqMap)
testDF["WorkToolsFrequencyPython"].fillna((testDF["WorkToolsFrequencyPython"].median()), inplace=True)

testDF["WorkToolsFrequencyR"] = testDF["WorkToolsFrequencyR"].replace(freqMap)
testDF["WorkToolsFrequencyR"].fillna((testDF["WorkToolsFrequencyR"].median()), inplace=True)

testDF["WorkToolsFrequencySQL"] = testDF["WorkToolsFrequencySQL"].replace(freqMap)
testDF["WorkToolsFrequencySQL"].fillna((testDF["WorkToolsFrequencySQL"].median()), inplace=True)

trainDF["WorkMethodsFrequencyCross-Validation"] = trainDF["WorkMethodsFrequencyCross-Validation"].replace(freqMap)
trainDF["WorkMethodsFrequencyCross-Validation"].fillna((trainDF["WorkMethodsFrequencyCross-Validation"].median()), inplace=True)


trainDF["WorkMethodsFrequencyDataVisualization"] = trainDF["WorkMethodsFrequencyDataVisualization"].replace(freqMap)
trainDF["WorkMethodsFrequencyDataVisualization"].fillna((trainDF["WorkMethodsFrequencyDataVisualization"].median()), inplace=True)


trainDF["WorkMethodsFrequencyLogisticRegression"] = trainDF["WorkMethodsFrequencyLogisticRegression"].replace(freqMap)
trainDF["WorkMethodsFrequencyLogisticRegression"].fillna((trainDF["WorkMethodsFrequencyLogisticRegression"].median()), inplace=True)


trainDF["WorkChallengeFrequencyDirtyData"] = trainDF["WorkChallengeFrequencyDirtyData"].replace(freqMap)
trainDF["WorkChallengeFrequencyDirtyData"].fillna((trainDF["WorkChallengeFrequencyDirtyData"].median()), inplace=True)


trainDF["WorkChallengeFrequencyExplaining"] = trainDF["WorkChallengeFrequencyExplaining"].replace(freqMap)
trainDF["WorkChallengeFrequencyExplaining"].fillna((trainDF["WorkChallengeFrequencyExplaining"].median()), inplace=True)


trainDF["WorkChallengeFrequencyTalent"] = trainDF["WorkChallengeFrequencyTalent"].replace(freqMap)
trainDF["WorkChallengeFrequencyTalent"].fillna((trainDF["WorkChallengeFrequencyTalent"].median()), inplace=True)


trainDF["WorkChallengeFrequencyClarity"] = trainDF["WorkChallengeFrequencyClarity"].replace(freqMap)
trainDF["WorkChallengeFrequencyClarity"].fillna((trainDF["WorkChallengeFrequencyClarity"].median()), inplace=True)


trainDF["WorkChallengeFrequencyDataAccess"] = trainDF["WorkChallengeFrequencyDataAccess"].replace(freqMap)
trainDF["WorkChallengeFrequencyDataAccess"].fillna((trainDF["WorkChallengeFrequencyDataAccess"].median()), inplace=True)


trainDF["WorkMethodsFrequencyNeuralNetworks"] = trainDF["WorkMethodsFrequencyNeuralNetworks"].replace(freqMap)
trainDF["WorkMethodsFrequencyNeuralNetworks"].fillna((trainDF["WorkMethodsFrequencyNeuralNetworks"].median()), inplace=True)


trainDF["WorkMethodsFrequencyPCA"] = trainDF["WorkMethodsFrequencyPCA"].replace(freqMap)
trainDF["WorkMethodsFrequencyPCA"].fillna((trainDF["WorkMethodsFrequencyPCA"].median()), inplace=True)


trainDF["WorkMethodsFrequencyRandomForests"] = trainDF["WorkMethodsFrequencyRandomForests"].replace(freqMap)
trainDF["WorkMethodsFrequencyRandomForests"].fillna((trainDF["WorkMethodsFrequencyRandomForests"].median()), inplace=True)


trainDF["WorkMethodsFrequencyTimeSeriesAnalysis"] = trainDF["WorkMethodsFrequencyTimeSeriesAnalysis"].replace(freqMap)
trainDF["WorkMethodsFrequencyTimeSeriesAnalysis"].fillna((trainDF["WorkMethodsFrequencyTimeSeriesAnalysis"].median()), inplace=True)


trainDF["WorkChallengeFrequencyPolitics"] = trainDF["WorkChallengeFrequencyPolitics"].replace(freqMap)
trainDF["WorkChallengeFrequencyPolitics"].fillna((trainDF["WorkChallengeFrequencyPolitics"].median()), inplace=True)

trainDF["WorkChallengeFrequencyUnusedResults"] = trainDF["WorkChallengeFrequencyUnusedResults"].replace(freqMap)
trainDF["WorkChallengeFrequencyUnusedResults"].fillna((trainDF["WorkChallengeFrequencyUnusedResults"].median()), inplace=True)

trainDF["WorkMethodsFrequencyDecisionTrees"] = trainDF["WorkMethodsFrequencyDecisionTrees"].replace(freqMap)
trainDF["WorkMethodsFrequencyDecisionTrees"].fillna((trainDF["WorkMethodsFrequencyDecisionTrees"].median()), inplace=True)






testDF["WorkMethodsFrequencyCross-Validation"] = testDF["WorkMethodsFrequencyCross-Validation"].replace(freqMap)
testDF["WorkMethodsFrequencyCross-Validation"].fillna((testDF["WorkMethodsFrequencyCross-Validation"].median()), inplace=True)


testDF["WorkMethodsFrequencyDataVisualization"] = testDF["WorkMethodsFrequencyDataVisualization"].replace(freqMap)
testDF["WorkMethodsFrequencyDataVisualization"].fillna((testDF["WorkMethodsFrequencyDataVisualization"].median()), inplace=True)


testDF["WorkMethodsFrequencyLogisticRegression"] = testDF["WorkMethodsFrequencyLogisticRegression"].replace(freqMap)
testDF["WorkMethodsFrequencyLogisticRegression"].fillna((testDF["WorkMethodsFrequencyLogisticRegression"].median()), inplace=True)


testDF["WorkChallengeFrequencyDirtyData"] = testDF["WorkChallengeFrequencyDirtyData"].replace(freqMap)
testDF["WorkChallengeFrequencyDirtyData"].fillna((testDF["WorkChallengeFrequencyDirtyData"].median()), inplace=True)


testDF["WorkChallengeFrequencyExplaining"] = testDF["WorkChallengeFrequencyExplaining"].replace(freqMap)
testDF["WorkChallengeFrequencyExplaining"].fillna((testDF["WorkChallengeFrequencyExplaining"].median()), inplace=True)


testDF["WorkChallengeFrequencyTalent"] = testDF["WorkChallengeFrequencyTalent"].replace(freqMap)
testDF["WorkChallengeFrequencyTalent"].fillna((testDF["WorkChallengeFrequencyTalent"].median()), inplace=True)


testDF["WorkChallengeFrequencyClarity"] = testDF["WorkChallengeFrequencyClarity"].replace(freqMap)
testDF["WorkChallengeFrequencyClarity"].fillna((testDF["WorkChallengeFrequencyClarity"].median()), inplace=True)


testDF["WorkChallengeFrequencyDataAccess"] = testDF["WorkChallengeFrequencyDataAccess"].replace(freqMap)
testDF["WorkChallengeFrequencyDataAccess"].fillna((testDF["WorkChallengeFrequencyDataAccess"].median()), inplace=True)


testDF["WorkMethodsFrequencyNeuralNetworks"] = testDF["WorkMethodsFrequencyNeuralNetworks"].replace(freqMap)
testDF["WorkMethodsFrequencyNeuralNetworks"].fillna((testDF["WorkMethodsFrequencyNeuralNetworks"].median()), inplace=True)


testDF["WorkMethodsFrequencyPCA"] = testDF["WorkMethodsFrequencyPCA"].replace(freqMap)
testDF["WorkMethodsFrequencyPCA"].fillna((testDF["WorkMethodsFrequencyPCA"].median()), inplace=True)


testDF["WorkMethodsFrequencyRandomForests"] = testDF["WorkMethodsFrequencyRandomForests"].replace(freqMap)
testDF["WorkMethodsFrequencyRandomForests"].fillna((testDF["WorkMethodsFrequencyRandomForests"].median()), inplace=True)


testDF["WorkMethodsFrequencyTimeSeriesAnalysis"] = testDF["WorkMethodsFrequencyTimeSeriesAnalysis"].replace(freqMap)
testDF["WorkMethodsFrequencyTimeSeriesAnalysis"].fillna((testDF["WorkMethodsFrequencyTimeSeriesAnalysis"].median()), inplace=True)


testDF["WorkChallengeFrequencyPolitics"] = testDF["WorkChallengeFrequencyPolitics"].replace(freqMap)
testDF["WorkChallengeFrequencyPolitics"].fillna((testDF["WorkChallengeFrequencyPolitics"].median()), inplace=True)

testDF["WorkChallengeFrequencyUnusedResults"] = testDF["WorkChallengeFrequencyUnusedResults"].replace(freqMap)
testDF["WorkChallengeFrequencyUnusedResults"].fillna((testDF["WorkChallengeFrequencyUnusedResults"].median()), inplace=True)

testDF["WorkMethodsFrequencyDecisionTrees"] = testDF["WorkMethodsFrequencyDecisionTrees"].replace(freqMap)
testDF["WorkMethodsFrequencyDecisionTrees"].fillna((testDF["WorkMethodsFrequencyDecisionTrees"].median()), inplace=True)

formalEduMap =  {}

i = 0
for elt in trainDF["FormalEducation"].unique():
  formalEduMap[elt] = i
  i = i+1


for k,v in formalEduMap.items():
  if v == 7:
    formalEduMap.pop(k)
    break

trainDF["FormalEducation"] = trainDF["FormalEducation"].replace(formalEduMap)
trainDF["FormalEducation"].fillna((trainDF["FormalEducation"].median()), inplace=True)

testDF["FormalEducation"] = testDF["FormalEducation"].replace(formalEduMap)
testDF["FormalEducation"].fillna((testDF["FormalEducation"].median()), inplace=True)

scientistMap = {}
i = 0
for elt in trainDF["DataScienceIdentitySelect"].unique():
  scientistMap[elt] = i
  i = i+1

for k,v in scientistMap.items():
  if v == 2:
    scientistMap.pop(k)
    break

trainDF["DataScienceIdentitySelect"] = trainDF["DataScienceIdentitySelect"].replace(scientistMap)
trainDF["DataScienceIdentitySelect"].fillna((trainDF["DataScienceIdentitySelect"].median()), inplace=True)

testDF["DataScienceIdentitySelect"] = testDF["DataScienceIdentitySelect"].replace(scientistMap)
testDF["DataScienceIdentitySelect"].fillna((testDF["DataScienceIdentitySelect"].median()), inplace=True)

titleMap = {}
i = 0
for elt in trainDF["TitleFit"].unique():
  titleMap[elt] = i
  i = i+1

for k,v in scientistMap.items():
  if v == 3:
    scientistMap.pop(k)
    break

trainDF["TitleFit"] = trainDF["TitleFit"].replace(titleMap)
trainDF["TitleFit"].fillna((trainDF["TitleFit"].median()), inplace=True)

testDF["TitleFit"] = testDF["TitleFit"].replace(titleMap)
testDF["TitleFit"].fillna((testDF["TitleFit"].median()), inplace=True)

foundUsefulMap = {}
i = 0
for elt in trainDF["LearningPlatformUsefulnessKaggle"].unique():
  foundUsefulMap[elt] = i
  i = i+1
for k,v in foundUsefulMap.items():
  if v == 0:
    foundUsefulMap.pop(k)
    break

trainDF["LearningPlatformUsefulnessKaggle"] = trainDF["LearningPlatformUsefulnessKaggle"].replace(foundUsefulMap)
trainDF["LearningPlatformUsefulnessKaggle"].fillna((trainDF["LearningPlatformUsefulnessKaggle"].median()), inplace=True)

trainDF["LearningPlatformUsefulnessCourses"] = trainDF["LearningPlatformUsefulnessCourses"].replace(foundUsefulMap)
trainDF["LearningPlatformUsefulnessCourses"].fillna((trainDF["LearningPlatformUsefulnessCourses"].median()), inplace=True)

trainDF["LearningPlatformUsefulnessProjects"] = trainDF["LearningPlatformUsefulnessProjects"].replace(foundUsefulMap)
trainDF["LearningPlatformUsefulnessProjects"].fillna((trainDF["LearningPlatformUsefulnessProjects"].median()), inplace=True)

trainDF["LearningPlatformUsefulnessSO"] = trainDF["LearningPlatformUsefulnessSO"].replace(foundUsefulMap)
trainDF["LearningPlatformUsefulnessSO"].fillna((trainDF["LearningPlatformUsefulnessSO"].median()), inplace=True)

trainDF["LearningPlatformUsefulnessTextbook"] = trainDF["LearningPlatformUsefulnessTextbook"].replace(foundUsefulMap)
trainDF["LearningPlatformUsefulnessTextbook"].fillna((trainDF["LearningPlatformUsefulnessTextbook"].median()), inplace=True)


testDF["LearningPlatformUsefulnessKaggle"] = testDF["LearningPlatformUsefulnessKaggle"].replace(foundUsefulMap)
testDF["LearningPlatformUsefulnessKaggle"].fillna((testDF["LearningPlatformUsefulnessKaggle"].median()), inplace=True)

testDF["LearningPlatformUsefulnessCourses"] = testDF["LearningPlatformUsefulnessCourses"].replace(foundUsefulMap)
testDF["LearningPlatformUsefulnessCourses"].fillna((testDF["LearningPlatformUsefulnessCourses"].median()), inplace=True)

testDF["LearningPlatformUsefulnessProjects"] = testDF["LearningPlatformUsefulnessProjects"].replace(foundUsefulMap)
testDF["LearningPlatformUsefulnessProjects"].fillna((testDF["LearningPlatformUsefulnessProjects"].median()), inplace=True)

testDF["LearningPlatformUsefulnessSO"] = testDF["LearningPlatformUsefulnessSO"].replace(foundUsefulMap)
testDF["LearningPlatformUsefulnessSO"].fillna((testDF["LearningPlatformUsefulnessSO"].median()), inplace=True)

testDF["LearningPlatformUsefulnessTextbook"] = testDF["LearningPlatformUsefulnessTextbook"].replace(foundUsefulMap)
testDF["LearningPlatformUsefulnessTextbook"].fillna((testDF["LearningPlatformUsefulnessTextbook"].median()), inplace=True)

trainDF["LearningPlatformUsefulnessYouTube"] = trainDF["LearningPlatformUsefulnessYouTube"].replace(foundUsefulMap)
trainDF["LearningPlatformUsefulnessYouTube"].fillna((trainDF["LearningPlatformUsefulnessYouTube"].median()), inplace=True)

trainDF["LearningPlatformUsefulnessBlogs"] = trainDF["LearningPlatformUsefulnessBlogs"].replace(foundUsefulMap)
trainDF["LearningPlatformUsefulnessBlogs"].fillna((trainDF["LearningPlatformUsefulnessBlogs"].median()), inplace=True)

testDF["LearningPlatformUsefulnessYouTube"] = testDF["LearningPlatformUsefulnessYouTube"].replace(foundUsefulMap)
testDF["LearningPlatformUsefulnessYouTube"].fillna((testDF["LearningPlatformUsefulnessYouTube"].median()), inplace=True)

testDF["LearningPlatformUsefulnessBlogs"] = testDF["LearningPlatformUsefulnessBlogs"].replace(foundUsefulMap)
testDF["LearningPlatformUsefulnessBlogs"].fillna((testDF["LearningPlatformUsefulnessBlogs"].median()), inplace=True)

for col in trainDF.select_dtypes(include=np.number).columns.tolist():
  trainDF[col].fillna((trainDF[col].mean()), inplace=True)
  if col != "JobSatisfaction":
    testDF[col].fillna((testDF[col].mean()), inplace=True)

modified = ["Tenure","EmployerSize","WorkDataVisualizations","TitleFit","DataScienceIdentitySelect",
            "FormalEducation","WorkChallengeFrequencyDirtyData",'WorkProductionFrequency','WorkToolsFrequencyPython','WorkToolsFrequencyR',
                'WorkToolsFrequencySQL','WorkMethodsFrequencyCross-Validation','WorkMethodsFrequencyDataVisualization','LearningPlatformUsefulnessKaggle','LearningPlatformUsefulnessCourses',
               'LearningPlatformUsefulnessSO',"LearningPlatformUsefulnessYouTube","LearningPlatformUsefulnessBlogs","LearningPlatformUsefulnessProjects","LearningPlatformUsefulnessTextbook",
            'WorkChallengeFrequencyExplaining',
       'WorkChallengeFrequencyTalent', 'WorkChallengeFrequencyClarity',
       'WorkChallengeFrequencyDataAccess','WorkMethodsFrequencyNeuralNetworks', 'WorkMethodsFrequencyPCA',
       'WorkMethodsFrequencyRandomForests',
       'WorkMethodsFrequencyTimeSeriesAnalysis',
       'WorkChallengeFrequencyPolitics', 'WorkChallengeFrequencyUnusedResults',"MLTechniquesSelect","PastJobTitlesSelect"]

for col in trainDF.columns:
  if col not in modified:
    trainDF[col].fillna('None', inplace=True)
    if col != "JobSatisfaction":
      testDF[col].fillna('None', inplace=True)

trainDF.head()

encoders = list()
for col in trainDF.columns:
  if col not in modified and col != "JobSatisfaction" and col not in trainDF.select_dtypes(include=np.number).columns.tolist():
    enc = OneHotEncoder(handle_unknown='ignore')
    enc.fit_transform(trainDF[[col]]).toarray()

    xd = enc.fit_transform(trainDF[[col]]).toarray()
    xd = pd.DataFrame(xd,columns=enc.categories_)

    trainDF = pd.merge(trainDF,xd,right_index=True,left_index=True)
    trainDF = trainDF.drop(columns=col)

    testDF = pd.merge(testDF,xd,right_index=True,left_index=True)
    testDF = testDF.drop(columns=col)
trainDF.head()

"""# Trial Part

# Training Machine Learning Model
"""

X = trainDF.drop("JobSatisfaction",axis=1)
Y = trainDF["JobSatisfaction"]

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)

"""Linear Regression Model"""

from sklearn import linear_model
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score 

model = linear_model.LinearRegression()
model.fit(X_train, Y_train)

# Commented out IPython magic to ensure Python compatibility.
Y_pred_train = model.predict(X_test)

print('Mean squared error (MSE): %.2f'
#       % mean_squared_error(Y_test, Y_pred_train))
print('Coefficient of determination (R^2): %.2f'
#       % r2_score(Y_test, Y_pred_train))

# Commented out IPython magic to ensure Python compatibility.
from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier(criterion = 'entropy', max_depth = 3)
model.fit(X_train, Y_train)

Y_pred_train = model.predict(X_test)

print('Mean squared error (MSE): %.2f'
#       % mean_squared_error(Y_test, Y_pred_train))
print('Coefficient of determination (R^2): %.2f'
#       % r2_score(Y_test, Y_pred_train))

Y_pred_test = model.predict(testDF)
import csv
with open('/content/drive/MyDrive/predictions.csv', 'w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(["ID", "Prediction"])
    i = 1
    for pred in Y_pred_test:     
      writer.writerow([i,pred])
      i = i+1

from google.colab import drive
drive.mount('/content/drive')

"""kNN Algorithm"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.neighbors import KNeighborsClassifier

# initialize the values of k to be a list of odd numbers between 1 and 30
kVals = [(2*i+1) for i in range(15)]

# Save the accuracies of each value of kVal in [accuracies] variable
accuracies = []

# loop over values of k for the k-Nearest Neighbor classifier
for k in kVals:
  
  # Train the k-Nearest Neighbor classifier with the current value of k
  model = KNeighborsClassifier(n_neighbors=k, metric = 'minkowski', p=2)
  model.fit(X_train, Y_train)
  
  # Evaluate the model on validation set 
  score = model.score(X_test, Y_test)
  print("For k = %d, validation accuracy = %.5f%%" % (k, score * 100))
  
  # Update the accuracies list
  accuracies.append(score)
print('Mean squared error (MSE): %.2f'
#       % mean_squared_error(Y_test, model.predict(X_test)))

"""Neural Network"""

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
scaler.fit(X_train)
X_train=scaler.transform(X_train)
X_test=scaler.transform(X_test)

from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam

model = Sequential([Dense(128, activation='relu'),
                    Dropout(0.5),
                    Dense(128, activation='relu'),
                    Dropout(0.5),
                    Dense(11, activation='softmax')])

model.compile(loss='sparse_categorical_crossentropy',
              optimizer=Adam(),
              metrics=['mean_squared_error','accuracy'])
history = model.fit(
    X_train, 
    Y_train, 
    batch_size=32, 
    epochs=30, 
    validation_split = 0.2,
    verbose=1)

model.predict(testDF)

